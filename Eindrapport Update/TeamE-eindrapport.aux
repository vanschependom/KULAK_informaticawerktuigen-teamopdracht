\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\catcode `"\active 
\babel@aux{dutch}{}
\pgfsyspdfmark {pgfid2}{0}{0}
\pgfsyspdfmark {pgfid1}{5682080}{48079844}
\citation{tumoronderzoek}
\citation{tumordataset}
\citation{tumoronderzoek}
\citation{tumoronderzoek}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Gedigitaliseerde beelden van fijne naaldaspiraten van de borstmassa. \cite  {tumoronderzoek}\relax }}{3}{figure.caption.5}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:borstscan}{{1}{3}{Gedigitaliseerde beelden van fijne naaldaspiraten van de borstmassa. \cite {tumoronderzoek}\relax }{figure.caption.5}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Situering van SVM binnen machine learning}{4}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Wat is machine learning?}{4}{section.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Terminologie en notatie}{4}{section.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Supervised learning}{5}{section.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.1}Uitbreiding van de notatie}{5}{subsection.1.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Classificatie}{5}{section.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Het \textit  {maximum margin}-principe}{6}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}De hypervlakken}{6}{section.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.2}De marge maximaliseren}{6}{section.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Twee lineair scheidbare wolken van punten. De kleuren van de punten duiden aan tot welke klasse ze behoren.\relax }}{7}{figure.caption.6}\protected@file@percent }
\newlabel{fig:svm}{{2.1}{7}{Twee lineair scheidbare wolken van punten. De kleuren van de punten duiden aan tot welke klasse ze behoren.\relax }{figure.caption.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}\textit  {Hinge loss}}{7}{subsection.2.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}De kostfunctie}{7}{subsection.2.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {3}De regularisatieparameter \(\lambda \)}{9}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Wat is een metaparameter?}{9}{section.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Het belang van de regularisatieparameter}{9}{section.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Bias}{9}{subsection.3.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces De invloed van de metaparameter \(\lambda \) op het SVM-model. Een grote \(\lambda \) resulteert in een grote marge, een kleine \(\lambda \) resulteert in een kleine marge.\relax }}{10}{figure.caption.7}\protected@file@percent }
\newlabel{fig:lambda}{{3.1}{10}{De invloed van de metaparameter \(\lambda \) op het SVM-model. Een grote \(\lambda \) resulteert in een grote marge, een kleine \(\lambda \) resulteert in een kleine marge.\relax }{figure.caption.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Variantie}{11}{subsection.3.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.3}\textit  {Bias-variance trade-off}}{11}{section.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.4}\textit  {Cross-validation}}{12}{section.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.1}De data opsplitsen}{12}{subsection.3.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.2}Itereren over verschillende waardes voor \(\lambda \)}{12}{subsection.3.4.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces De accuraatheid van het model t.o.v. de validatiedata, uitgezet in functie van de metaparameter \(\lambda \) voor ons SVM-model.\relax }}{13}{figure.caption.8}\protected@file@percent }
\newlabel{fig:metaparameter}{{3.2}{13}{De accuraatheid van het model t.o.v. de validatiedata, uitgezet in functie van de metaparameter \(\lambda \) voor ons SVM-model.\relax }{figure.caption.8}{}}
\citation{Luca_2022}
\citation{Luca_2022}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Vergelijking met andere classificatietechnieken}{14}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Deze figuur uit bron \cite  {Luca_2022} geeft een belangrijk verschil tussen een neuraal netwerk en een SVM model weer. Links wordt de werking van een neuraal netwerk geïllustreerd, rechts die van een SVM model. Hierbij valt op dat de kans dat een nieuw datapunt juist geclassificeerd zal worden, veel groter is bij SVM. Deze figuur benadrukt dus ook belang van het \textit  {maximum margin} hypervlak bij het voorkomen van \textit  {overfitting}. \relax }}{14}{figure.caption.9}\protected@file@percent }
\newlabel{fig:NeuralNetsVsSVM}{{4.1}{14}{Deze figuur uit bron \cite {Luca_2022} geeft een belangrijk verschil tussen een neuraal netwerk en een SVM model weer. Links wordt de werking van een neuraal netwerk geïllustreerd, rechts die van een SVM model. Hierbij valt op dat de kans dat een nieuw datapunt juist geclassificeerd zal worden, veel groter is bij SVM. Deze figuur benadrukt dus ook belang van het \textit {maximum margin} hypervlak bij het voorkomen van \textit {overfitting}. \relax }{figure.caption.9}{}}
\citation{Ramo_2017}
\citation{Ramo_2017}
\citation{bzdok2018machine}
\citation{bzdok2018machine}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Deze figuur uit bron \cite  {Ramo_2017} toont de vergelijking tussen SVM en logistische regressie. Hierbij valt het duidelijk op dat wanneer er sprake is van een \textit  {outlier}, logistische regressie zich heel hard aanpast aan deze \textit  {outlier}. Dit toont dan aan dat Support Vector Machines veel beter bestendig zijn tegen ruis in de dataset. \relax }}{15}{figure.caption.10}\protected@file@percent }
\newlabel{fig:LogistischeRegressieVsSVM}{{4.2}{15}{Deze figuur uit bron \cite {Ramo_2017} toont de vergelijking tussen SVM en logistische regressie. Hierbij valt het duidelijk op dat wanneer er sprake is van een \textit {outlier}, logistische regressie zich heel hard aanpast aan deze \textit {outlier}. Dit toont dan aan dat Support Vector Machines veel beter bestendig zijn tegen ruis in de dataset. \relax }{figure.caption.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Deze figuur uit bron \cite  {bzdok2018machine} vergelijkt KNN-classificatie met SVM-classificatie. Bij de eerste van de twee technieken ontstaan er twee twee gebieden, die worden bepaald door naar de \(k\) dichtste buren te kijken van elk datapunt. Op de linkerfiguur is \(k=3\), op de rechterfiguur is \(k=7\). Met behulp van \textit  {cross-validation} werd bepaald dat \(k=7\) de optimale waarde is voor de metaparameter \(k\), met een accuraatheid van 87\%. De rechte die door de grafiek gaat, is de beslissingsgrens van SVM en de stippellijnen zijn hypervlakken. Hierbij valt het duidelijk op dat SVM veel makkelijker te interpreteren is in vergelijking met KNN, terwijl de accuraatheid van SVM nog steeds gelijk is aan 85\% in dit voorbeeld. We boeten, door gebruik te maken van SVM, dus een slechts een klein beetje in op accuraatheid, maar dit is in het voordeel van de interpreteerbaarheid van het model.\relax }}{16}{figure.caption.11}\protected@file@percent }
\newlabel{fig:KNNvsSVM}{{4.3}{16}{Deze figuur uit bron \cite {bzdok2018machine} vergelijkt KNN-classificatie met SVM-classificatie. Bij de eerste van de twee technieken ontstaan er twee twee gebieden, die worden bepaald door naar de \(k\) dichtste buren te kijken van elk datapunt. Op de linkerfiguur is \(k=3\), op de rechterfiguur is \(k=7\). Met behulp van \textit {cross-validation} werd bepaald dat \(k=7\) de optimale waarde is voor de metaparameter \(k\), met een accuraatheid van 87\%. De rechte die door de grafiek gaat, is de beslissingsgrens van SVM en de stippellijnen zijn hypervlakken. Hierbij valt het duidelijk op dat SVM veel makkelijker te interpreteren is in vergelijking met KNN, terwijl de accuraatheid van SVM nog steeds gelijk is aan 85\% in dit voorbeeld. We boeten, door gebruik te maken van SVM, dus een slechts een klein beetje in op accuraatheid, maar dit is in het voordeel van de interpreteerbaarheid van het model.\relax }{figure.caption.11}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Resultaten op onze dataset}{17}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}\textit  {Features}}{17}{section.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.1}Limitaties}{17}{subsection.5.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Een \textit  {pairplot} van de eerste 5 \textit  {features} in de tumordataset.\relax }}{18}{figure.caption.12}\protected@file@percent }
\newlabel{fig:pairplot}{{5.1}{18}{Een \textit {pairplot} van de eerste 5 \textit {features} in de tumordataset.\relax }{figure.caption.12}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.2}Selectie}{18}{subsection.5.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Evaluatie van de accuraatheid}{18}{section.5.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces Ons SVM model toegepast op de testdata. We konden een accuraatheid van \(89,51\%\) bewerkstelligen.\relax }}{19}{figure.caption.13}\protected@file@percent }
\newlabel{fig:testdata}{{5.2}{19}{Ons SVM model toegepast op de testdata. We konden een accuraatheid van \(89,51\%\) bewerkstelligen.\relax }{figure.caption.13}{}}
\citation{enwiki:1183475870}
\citation{mediumarticle}
\citation{bzdok2018machine}
\bibstyle{unsrt}
\bibdata{referenties}
\bibcite{tumoronderzoek}{1}
\bibcite{tumordataset}{2}
\bibcite{Luca_2022}{3}
\bibcite{Ramo_2017}{4}
\bibcite{bzdok2018machine}{5}
\bibcite{enwiki:1183475870}{6}
\bibcite{mediumarticle}{7}
\pgfsyspdfmark {pgfid4}{0}{0}
\pgfsyspdfmark {pgfid3}{8031603}{48079844}
\gdef \@abspage@last{22}
